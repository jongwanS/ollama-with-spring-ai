spring:
  data:
    redis:
      host: localhost
      port: 6379
  ai:
    ollama:
      base-url: http://localhost:11434  # Ollama 서버 실행 중이어야 함
      chat:
        model: llama3.2  # 설치된 모델 이름 (예: llama3, mistral, phi)
      embedding:
        model: nomic-embed-text  # ← 여기를 추가!
    vectorstore:
      redis:
        initialize-schema: true
        index-name: spring-ai-index
        prefix: custom-prefix

#spring:
#  ai:
#    ollama:
#      base-url: http://localhost:11434
#      chat:
#        options:
#          model: gemma3:4b
#          temperature: 0.7
# FT.CREATE spring-ai-index ON JSON PREFIX 1 embedding: SCHEMA $.embedding VECTOR FLAT 6 TYPE FLOAT32 DIM 768 DISTANCE_METRIC COSINE